# Terminologies in ML

## Overfitting
Overfitting in machine learning is when a model learns the training data too well, including all the noise and random fluctuations, instead of just the underlying patterns. 
This means it performs great on the training data but poorly on new, unseen data.

#### In simple Simple words
overfitting is like memorizing answers instead of understanding the subject, leading to poor performance when faced with new challenges!

#### Simple Expnation of overfitting
Example of Overfitting:
Imagine you are teaching a child to identify dogs. You show them many pictures of your dog, including all its unique features (like a collar or a specific background).
If the child only remembers those specific details, they might think that only your dog is a dog and fail to recognize other dogs that look different. This is similar to overfitting; 
the child memorizes the training data instead of learning the general concept of what a dog is.
